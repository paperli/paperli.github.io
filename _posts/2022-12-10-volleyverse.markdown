---
layout: post
title:  "Volleyverse"
short: "volleyverse"
tags:
    - "VR"
    - "AR"
    - "AI"
    - "UX"
    - "Hand Tracking"
    - "Oculus"
    - "3D"
    - "Prototype"
images: 
    - "/assets/images/cases/map/promo.jpg"

---
<!--summary-->

Step into the world of Volleyverse, where voice commands shape reality! Within a mere 24-hour hackathon, we manifested an enchanting "Making-A-Wish" experience exclusively for the Quest headsets. By seamlessly integrating the Wit.ai voice AI engine, users express their desires vocally, unveiling delightful gifts seamlessly integrated into their surroundings via the headset's passthrough feature. We presend our creation during the holiday season, serving as a conduit for spreading merriment and extending heartfelt Christmas wishes to all volley employees.

<!--more-->

> I want to make a wish and use the gifts to decorate my room.

Real world is intriguing, and the virtual world can make it fasinating. I groupped with another two VR enthusiastic during the internal Volley hackathon to explor the voice interactivity and capbability in mixed reality environment. Our vision is to make a platform and allow users to make wishes by their voice. We reveal their gift and they can move it around with grabbing and pictching hand gestures. In this way, we explore the voice interaction and showcase the intunity of voice interface on future mixed reality computing platforms.

I initialized the idea prior the hackathon and gathered 2 other VR enthusiastics at Volley to accomplish the prototype. I use my product design experiences to lead the product scoping conversation, and apply my Quest prototyping knowledges to draft the coding base. We highly cooperated druign the 24 hr spring and build the live demo in front of all Volley employees. 

<div style="padding:100% 0 0 0;position:relative;" class="video-embed"><iframe src="https://player.vimeo.com/video/504247535?color=c9ff23&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

The prototype implements 2 input modes, controller and hand tracking. The hand tracking mode provides the instinct interaction experience yet controllers serve precise scale and pan movement.

![VR Map Interaction](/assets/images/cases/map/controller1.jpg)

![VR Map Interaction](/assets/images/cases/map/hand2.jpg)

### Metropolis Model

Blender offers the convenient workflow to create metropolis with real world terrain by using the OSM plug-in. I choose Tokyo as the map basis to copy the high-rise and techno vibe of the city.

![OSM](/assets/images/cases/map/osm.png)

![Blender](/assets/images/cases/map/blender.png)

### Shader and Unity Universal RP

To represent the techno vibe of the map, the building landscape applies the custom shader to fade the bottom of the building and glow at the high elevation. With Unity Universal Render Pipeline, the shader can be made easily in Shader Graph. It improves the workflow for artists to create desired visual effects to a project.

![Unity](/assets/images/cases/map/unity.png)

The prototype shows the funny nature of the VR. The miniature city model inspires the joy and the instinct interaction can be very useful to the VR RPG and open-world games. It also makes me understand better to the story in Ready Player Two and reminds me of the VR's nature strength in representing the real-world scale replica. 

